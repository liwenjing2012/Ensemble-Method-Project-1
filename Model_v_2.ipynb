{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea44d16-ea08-47ab-9d6d-9190b3f73163",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608a912-eaf2-4bb5-8b80-79ac85073777",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27aa5d5-be3d-4050-b354-0fa0f97cbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import openpyxl\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "import pgeocode\n",
    "from geopy.distance import geodesic\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c47cd-a363-4ff0-ab87-1deeef46fa6e",
   "metadata": {},
   "source": [
    "### Read the excel files\n",
    "File including original Concentration, facilities details and distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49aec44-8e67-4042-9f61-adc25f116336",
   "metadata": {},
   "source": [
    "##### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff13145-614e-4e74-b218-a618f708475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/leichen/Desktop/WasteWater/data/Trace Organics Full.xlsx'\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None, skiprows=3)\n",
    "all_data = []\n",
    "sheets_to_exclude = ['Manhole 1', 'Manhole 2','Manhole 3']\n",
    "file_path1 = '/Users/leichen/Desktop/WasteWater/data/Facilities.xlsx'\n",
    "Facilities = pd.read_excel(file_path1, header=0)\n",
    "#Facilities['Population']=Facilities['Population']/1000\n",
    "Facilities['DailyFlow']=Facilities['DailyFlow']*3.78541\n",
    "file_path2 = '/Users/leichen/Desktop/WasteWater/data/Analytes.xlsx'\n",
    "Analytes = pd.read_excel(file_path2, header=0)\n",
    "file_path3 = '/Users/leichen/Desktop/WasteWater/data/ZipCodes.xlsx'\n",
    "Zips = pd.read_excel(file_path3,header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61bc0d-649d-43ca-a56f-51e695763676",
   "metadata": {},
   "source": [
    "##### Calculate the distance from the center of each facility to the center of Las Vegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe84732-1c20-40eb-b161-1bc0675d5de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid of Group Facility_1: (36.10901304347825, -115.17888260869564)\n",
      "Distance between the two centroids: 7.617 km\n",
      "Centroid of Group Facility_2: (35.94515, -115.14779999999999)\n",
      "Distance between the two centroids: 24.949 km\n",
      "Centroid of Group Facility_3: (36.20858947368422, -115.23982105263157)\n",
      "Distance between the two centroids: 9.968 km\n",
      "Centroid of Group Facility_4A: (36.047666666666665, -114.94993333333333)\n",
      "Distance between the two centroids: 21.822 km\n",
      "Centroid of Group Facility_4B: (36.03556666666666, -115.069)\n",
      "Distance between the two centroids: 16.212 km\n",
      "Centroid of Group Facility_5: (36.27775, -115.1738625)\n",
      "Distance between the two centroids: 12.353 km\n",
      "Centroid of Group Facility_6: (35.9727, -114.8344)\n",
      "Distance between the two centroids: 35.152 km\n",
      "Centroid of Group Facility_4: (36.04161666666666, -115.00946666666668)\n",
      "Distance between the two centroids: 18.448 km\n"
     ]
    }
   ],
   "source": [
    "nomi = pgeocode.Nominatim('us')  # 'us' for United States\n",
    "facilityList = []\n",
    "distanceList = []\n",
    " \n",
    "# Calculate the centroid (center of the group)\n",
    "def calculate_centroid(coords):\n",
    "    lats, longs = zip(*coords)\n",
    "    return (np.mean(lats), np.mean(longs))\n",
    "\n",
    "las_vegas_coords = (36.1699, -115.1398)\n",
    "    \n",
    "for k in Zips['Facility'].unique(): \n",
    "    zip_codes_group = Zips[Zips['Facility']==k]\n",
    "    zip_group = [(nomi.query_postal_code(z).latitude, nomi.query_postal_code(z).longitude) for z in zip_codes_group['ZipCode']]\n",
    "    centroid = calculate_centroid(zip_group)\n",
    "    # globals()f'zip_codes_{k}' = zip_group\n",
    "    distance_to_las_vegas = geodesic(centroid, las_vegas_coords).kilometers\n",
    "    facilityList.append(k)\n",
    "    distanceList.append(distance_to_las_vegas)\n",
    "    zip_distances = pd.DataFrame({\n",
    "        'Facility': facilityList,\n",
    "        'Distance': distanceList\n",
    "    })\n",
    "    print(f\"Centroid of Group {k}:\", centroid)\n",
    "    print(f\"Distance between the two centroids: {distance_to_las_vegas:.3f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c2c71-1251-4d51-af7a-b0f7d161ef7e",
   "metadata": {},
   "source": [
    "##### Pre-process & merge the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802913db-0180-478b-bec5-911dd4565c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, df in all_sheets.items():\n",
    "    if date not in sheets_to_exclude:\n",
    "        # Select the relevant columns: Analyte and Facilities (3rd column onwards)\n",
    "        df_relevant = df.iloc[:, [1]+list(range(3,11))]  # 1st, 3rd to 10th columns\n",
    "        \n",
    "        # Rename the columns for ease of reference\n",
    "        df_relevant.columns = ['Analyte', 'Facility_1', 'Facility_2', 'Facility_3', 'Facility_4', 'Facility_4A', 'Facility_4B', 'Facility_5', 'Facility_6']\n",
    "        \n",
    "        # Melt the DataFrame to convert wide format to long format\n",
    "        df_melted = df_relevant.melt(id_vars=['Analyte'], var_name='Facility', value_name='Consumption')\n",
    "        \n",
    "        # Add the 'Date' column (sheet name, representing the date)\n",
    "        df_melted['Date'] = date\n",
    "        \n",
    "        # Append the transformed DataFrame to the list\n",
    "        all_data.append(df_melted)\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df['Consumption'] = final_df['Consumption'].astype(str)\n",
    "final_df['Consumption']= pd.to_numeric(final_df['Consumption'].str.replace('<', ''), errors='coerce')\n",
    "final_df['Date']=pd.to_datetime(final_df['Date'],format = '%m_%d_%y')\n",
    "final_data = pd.merge(final_df,Facilities,on='Facility')\n",
    "final_data = pd.merge(final_data, Analytes, on='Analyte',how='left')\n",
    "final_data = pd.merge(final_data, zip_distances,on='Facility',how = 'left')\n",
    "#final_data['Consump1']=(final_data['Consumption']*final_data['CF']*final_data['DailyFlow'])/(final_data['Population'])\n",
    "final_data['Consump1']=(final_data['Consumption']*final_data['DailyFlow'])/(final_data['Population'])\n",
    "final_data1 = final_data.copy()\n",
    "final_data1.index = pd.to_datetime(final_data1['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dfea7-cdd0-4299-9992-6cdd565cc71f",
   "metadata": {},
   "source": [
    "##### Functions\n",
    "1. create_lag: create previous consumption & consumption two months ago\n",
    "2. create_features: date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f89af060-caa9-4560-95aa-6ba0ab2a426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag(data, cov, lag):\n",
    "    # Check if 'cov' is a single column or a list, and handle both cases\n",
    "    if isinstance(cov, str):\n",
    "        cov = [cov]  # Convert to a list if it's a single column name\n",
    "    \n",
    "    # Loop over the specified lags and create lagged columns\n",
    "    for i in range(1, lag + 1):\n",
    "        data[f'lag_{i}'] = data.groupby(cov)['Consump1'].shift(i)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b83349-acbe-4014-a820-43849a0d9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create time-based features such as hour of the day, day of the week, etc.\n",
    "    \"\"\"\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['weekofyear'] = df.index.isocalendar().week\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d28ade-cf09-44e5-be5f-529dfe319c4c",
   "metadata": {},
   "source": [
    "##### Prepare the datasets for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52978487-444b-44c4-88d5-ff68b97ed159",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = create_lag(final_data1, ['Facility','Analyte'],1)\n",
    "data_input = create_lag(final_data1, ['Facility','Analyte'],2)\n",
    "data_input = create_features(data_input)\n",
    "# data_input['Facility'] = data_input['Facility'].astype('category')\n",
    "data_input['DetailedCat'] = data_input['DetailedCat'].astype('category')\n",
    "data_input['Analyte'] = data_input['Analyte'].astype('category')\n",
    "data_input= data_input.dropna(subset=['lag_1','lag_2'])\n",
    "\n",
    "# d2 = data_input.sort_values(by=['Analyte', 'Facility'], ascending=[True, True])\n",
    "# d2.to_excel('/Users/leichen/Desktop/WasteWater/results/2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e2896-ab4c-48b2-bd6b-489c37e19fa1",
   "metadata": {},
   "source": [
    "##### Create functions\n",
    "1. split_train_test : split the training datasets\n",
    "2. x_y: give X_training, Y_training, X_test, Y_test\n",
    "3. xgb_based: build base XGB model\n",
    "4. naive_forecast: build naive model\n",
    "5. plot_pred_true: plots compare predicted values vs True values\n",
    "6. plot_difference: plots the difference between naive rmse - xgb rmse\n",
    "7. xgb_method: general xgb method\n",
    "8. lightGBM method: general lightGBM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83b585a9-35e2-4c62-b913-d564eac44df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df,percentage):\n",
    "    train_size = int(len(df)*percentage)\n",
    "    split_date = df.iloc[:train_size].index[-1]\n",
    "    train = df.loc[df.index<= split_date]\n",
    "    test = df.loc[df.index>split_date]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2536dc55-4681-4ff9-abd8-ce9e939a2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y(df,pct,features, target):\n",
    "    train,test = split_train_test(df,pct)\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]\n",
    "    X_test = test[features]\n",
    "    y_test = test[target]\n",
    "    return X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c8b40eb-f2d0-4644-ba8f-8ef66a859af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_based(df,a,f,features,target):\n",
    "    reg = xgb.XGBRegressor(base_score=0.5,booster = 'gbtree',n_estimators=1000, early_stopping_rounds=50, max_depth=3, learning_rate=0.01, objective='reg:linear')\n",
    "    reg.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "    test['xgb_pred'] = reg.predict(X_test)\n",
    "    score = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "    return test, score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d0cb20-780d-4b8d-81a1-f627314e90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast(train, test):\n",
    "    # Forecast for each time step is simply the last value from the training data\n",
    "    rmse_naive = np.sqrt(mean_squared_error(test['Consump1'], test['lag_1']))\n",
    "    return rmse_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "414adf73-c3d0-47d8-bb29-4486f438eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_method(X_train,y_train,X_test,y_test,features):\n",
    "    model = xgb.XGBRegressor(enable_categorical=True, tree_method='gpu_hist' if 'category' in X_train.dtypes else 'auto')\n",
    "    model.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60b38815-c3aa-4df9-86f7-fc39c9cfdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LightGBM_method(X_train,y_train,X_test,y_test,categorical_features):\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "    # Define parameters for LightGBM\n",
    "    params = {\n",
    "        'objective': 'regression',  # Use 'regression' for predicting continuous values\n",
    "        'metric': 'rmse',           # Use root mean squared error for evaluation\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.1,\n",
    "        'verbose': -1,\n",
    "        }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, test_data],\n",
    "        callbacks=[early_stopping(stopping_rounds=10), log_evaluation(10)]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193e4f1-9201-4cc2-b710-2d206c10f5c9",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561ea08-b479-4f8f-8f03-7ac6cddffd73",
   "metadata": {},
   "source": [
    "#### General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4654aae1-20ee-4c6f-83a2-50af0482cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methods(method,f_new,pct,categorical_features):\n",
    "    features = ['month', 'quarter', 'weekofyear','lag_1','lag_2']\n",
    "    features.extend(f_new)\n",
    "    target = 'Consump1'\n",
    "    \n",
    "    data_input1=data_input.copy()\n",
    "    train, test = split_train_test(data_input1,pct)\n",
    "    X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "    score_naive = naive_forecast(train, test)\n",
    "    if method == 'XGB':\n",
    "        model = xgb_method(X_train,y_train,X_test,y_test,features)\n",
    "    else:\n",
    "        model = LightGBM_method(X_train,y_train,X_test,y_test,categorical_features)\n",
    "    test['xgb_pred'] = model.predict(X_test) \n",
    "    score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "    df_rmse = pd.DataFrame({\n",
    "        'Model':[method],\n",
    "        'Features': '+'.join(features),\n",
    "        'TrainingPct': [pct],\n",
    "        'GB_rmse': [score_xgb],\n",
    "        'Naive_rmse': [score_naive]\n",
    "    })\n",
    "    df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['GB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "    df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['GB_rmse']\n",
    "    return df_rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41a7b848-4fd1-4e7e-a72b-70d96e0250c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 6.43086\tvalid_1's rmse: 5.53805\n",
      "[20]\ttraining's rmse: 4.86706\tvalid_1's rmse: 3.84266\n",
      "[30]\ttraining's rmse: 4.41376\tvalid_1's rmse: 3.63784\n",
      "[40]\ttraining's rmse: 4.21612\tvalid_1's rmse: 3.63915\n",
      "[50]\ttraining's rmse: 4.04018\tvalid_1's rmse: 3.59954\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's rmse: 4.07108\tvalid_1's rmse: 3.56538\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>TrainingPct</th>\n",
       "      <th>GB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>month+quarter+weekofyear+lag_1+lag_2+DetailedC...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.565385</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.594363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model                                           Features  TrainingPct  \\\n",
       "0  LightGBM  month+quarter+weekofyear+lag_1+lag_2+DetailedC...          0.8   \n",
       "\n",
       "    GB_rmse  Naive_rmse smaller  Difference  \n",
       "0  3.565385    5.159748     xgb    1.594363  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods('LightGBM',['DetailedCat','Distance'],.8,['DetailedCat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb4caa-2bf0-4217-8d08-782247919124",
   "metadata": {},
   "source": [
    "## XGB models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cdb0be-1a8d-4130-9a04-aff1c649bc4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### XGB with only detailed categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c6a1405a-b136-43f6-8f66-21ad47b83983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:9.86033\tvalidation_1-rmse:9.52471\n",
      "[99]\tvalidation_0-rmse:1.08062\tvalidation_1-rmse:4.47275\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.472752</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.686996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_rmse  Naive_rmse smaller  Difference\n",
       "0  4.472752    5.159748     xgb    0.686996"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty lists to store the values\n",
    "xgb_list = []\n",
    "naive_list = []\n",
    "# features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','DetailedCat']\n",
    "features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','DetailedCat','Analyte']\n",
    "target = 'Consump1'\n",
    "pct = 0.8\n",
    "\n",
    "# data_input = data_input[data_input['Facility']!='Facility_4']\n",
    "\n",
    "data_input1=data_input.copy()\n",
    "train, test = split_train_test(data_input1,pct)\n",
    "X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "model = xgb.XGBRegressor(enable_categorical=True, tree_method='gpu_hist' if 'category' in X_train.dtypes else 'auto')\n",
    "model.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "test['xgb_pred'] = model.predict(X_test)\n",
    "score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "score_naive = naive_forecast(train, test)\n",
    "naive_list.append(score_naive)\n",
    "xgb_list.append(score_xgb)\n",
    "df_rmse = pd.DataFrame({\n",
    "    'XGB_rmse': xgb_list,\n",
    "    'Naive_rmse': naive_list\n",
    "})\n",
    "df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['XGB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['XGB_rmse']\n",
    "# df_rmse.to_excel('/Users/leichen/Desktop/WasteWater/results/rmse_comparison_Cat.xlsx', index=False)\n",
    "df_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c87b7-2934-4514-802a-94bdb66c37d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### With Distance and DetailedCat as categorical features_XGB native support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c60e3b5-d5a2-4989-8b83-8b32814db455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:9.82153\tvalidation_1-rmse:9.50522\n",
      "[99]\tvalidation_0-rmse:0.29051\tvalidation_1-rmse:4.05391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.053905</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.105842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_rmse  Naive_rmse smaller  Difference\n",
       "0  4.053905    5.159748     xgb    1.105842"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty lists to store the values\n",
    "xgb_list = []\n",
    "naive_list = []\n",
    "# features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Distance','DetailedCat']\n",
    "features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Distance','DetailedCat','Analyte']\n",
    "target = 'Consump1'\n",
    "pct = 0.8\n",
    "\n",
    "# data_input = data_input[data_input['Facility']!='Facility_4']\n",
    "\n",
    "data_input1=data_input.copy()\n",
    "train, test = split_train_test(data_input1,pct)\n",
    "X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "model = xgb.XGBRegressor(enable_categorical=True, tree_method='gpu_hist' if 'category' in X_train.dtypes else 'auto')\n",
    "model.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "test['xgb_pred'] = model.predict(X_test)\n",
    "score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "score_naive = naive_forecast(train, test)\n",
    "naive_list.append(score_naive)\n",
    "xgb_list.append(score_xgb)\n",
    "df_rmse = pd.DataFrame({\n",
    "    'XGB_rmse': xgb_list,\n",
    "    'Naive_rmse': naive_list\n",
    "})\n",
    "df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['XGB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['XGB_rmse']\n",
    "# df_rmse.to_excel('/Users/leichen/Desktop/WasteWater/results/rmse_comparison_Cat.xlsx', index=False)\n",
    "df_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f43f39-c3f4-4202-b622-d5b4e6018141",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### XGB method With Facility and DetailedCat as categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6869b205-8b71-414a-9950-7095196e7810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:9.73194\tvalidation_1-rmse:9.55615\n",
      "[99]\tvalidation_0-rmse:0.24612\tvalidation_1-rmse:3.50550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5055</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.654248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_rmse  Naive_rmse smaller  Difference\n",
       "0    3.5055    5.159748     xgb    1.654248"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty lists to store the values\n",
    "xgb_list = []\n",
    "naive_list = []\n",
    "# features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Facility','DetailedCat']\n",
    "features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Facility','DetailedCat','Analyte']\n",
    "target = 'Consump1'\n",
    "pct = 0.8\n",
    "\n",
    "# data_input = data_input[data_input['Facility']!='Facility_4']\n",
    "data_input['Facility'] = data_input['Facility'].astype('category')\n",
    "data_input1=data_input.copy()\n",
    "train, test = split_train_test(data_input1,pct)\n",
    "X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "model = xgb.XGBRegressor(enable_categorical=True, tree_method='gpu_hist' if 'category' in X_train.dtypes else 'auto')\n",
    "model.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "test['xgb_pred'] = model.predict(X_test)\n",
    "score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "score_naive = naive_forecast(train, test)\n",
    "naive_list.append(score_naive)\n",
    "xgb_list.append(score_xgb)\n",
    "df_rmse = pd.DataFrame({\n",
    "    'XGB_rmse': xgb_list,\n",
    "    'Naive_rmse': naive_list\n",
    "})\n",
    "df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['XGB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['XGB_rmse']\n",
    "# df_rmse.to_excel('/Users/leichen/Desktop/WasteWater/results/rmse_comparison_Cat.xlsx', index=False)\n",
    "df_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971dec27-1b01-45f7-bc94-4fd7bf331338",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c17f7-0426-414d-8901-315d15f1e857",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Light GBM with only detailedcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e0c81ce2-ea60-4c47-b81e-9b91b0744a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 6.51479\tvalid_1's rmse: 5.5178\n",
      "[20]\ttraining's rmse: 4.99804\tvalid_1's rmse: 3.88937\n",
      "[30]\ttraining's rmse: 4.63214\tvalid_1's rmse: 3.78603\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 4.76169\tvalid_1's rmse: 3.76329\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.763289</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.396459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_rmse  Naive_rmse smaller  Difference\n",
       "0  3.763289    5.159748     xgb    1.396459"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical_features = ['DetailedCat']\n",
    "# features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','DetailedCat']\n",
    "\n",
    "# Initialize empty lists to store the values\n",
    "xgb_list = []\n",
    "naive_list = []\n",
    "Analyte_list = []\n",
    "categorical_features = ['DetailedCat','Analyte']\n",
    "features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','DetailedCat','Analyte']\n",
    "target = 'Consump1'\n",
    "pct = 0.8\n",
    "\n",
    "# data_input['Facility'] = data_input['Facility'].astype('category')\n",
    "data_input1=data_input.copy()\n",
    "train, test = split_train_test(data_input1,pct)\n",
    "X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "# Convert data to LightGBM Dataset format and specify categorical features\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "# Define parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',  # Use 'regression' for predicting continuous values\n",
    "    'metric': 'rmse',           # Use root mean squared error for evaluation\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "model_lgb = lgb.train(\n",
    "params,\n",
    "train_data,\n",
    "valid_sets=[train_data, test_data],\n",
    "callbacks=[early_stopping(stopping_rounds=10), log_evaluation(10)]\n",
    ")\n",
    "\n",
    "test['xgb_pred'] = model_lgb.predict(X_test)\n",
    "score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "score_naive = naive_forecast(train, test)\n",
    "naive_list.append(score_naive)\n",
    "xgb_list.append(score_xgb)\n",
    "df_rmse = pd.DataFrame({\n",
    "    'XGB_rmse': xgb_list,\n",
    "    'Naive_rmse': naive_list\n",
    "})\n",
    "df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['XGB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['XGB_rmse']\n",
    "df_rmse\n",
    "\n",
    "# # Evaluate the model\n",
    "# rmse = root_mean_squared_error(y_test, y_pred, squared=False)\n",
    "# print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87d062-1a29-4e45-acd6-2b1c9c026f80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### LightGBM Facility & DetailedCat as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2dd3097-d629-4c1a-b2da-c177e1a92d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 6.51479\tvalid_1's rmse: 5.5178\n",
      "[20]\ttraining's rmse: 4.87278\tvalid_1's rmse: 3.81983\n",
      "[30]\ttraining's rmse: 4.43335\tvalid_1's rmse: 3.53355\n",
      "[40]\ttraining's rmse: 4.23491\tvalid_1's rmse: 3.46769\n",
      "[50]\ttraining's rmse: 4.10081\tvalid_1's rmse: 3.45095\n",
      "[60]\ttraining's rmse: 3.98453\tvalid_1's rmse: 3.49308\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 4.07319\tvalid_1's rmse: 3.42535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.425354</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.734394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_rmse  Naive_rmse smaller  Difference\n",
       "0  3.425354    5.159748     xgb    1.734394"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['Facility','DetailedCat']\n",
    "features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Facility','DetailedCat']\n",
    "# categorical_features = ['Facility','DetailedCat','Analyte']\n",
    "# features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Facility','DetailedCat','Analyte']\n",
    "# Initialize empty lists to store the values\n",
    "xgb_list = []\n",
    "naive_list = []\n",
    "Analyte_list = []\n",
    "\n",
    "\n",
    "target = 'Consump1'\n",
    "pct = 0.8\n",
    "\n",
    "# data_input['Facility'] = data_input['Facility'].astype('category')\n",
    "data_input1=data_input.copy()\n",
    "train, test = split_train_test(data_input1,pct)\n",
    "X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "# Convert data to LightGBM Dataset format and specify categorical features\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "# Define parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',  # Use 'regression' for predicting continuous values\n",
    "    'metric': 'rmse',           # Use root mean squared error for evaluation\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "model_lgb = lgb.train(\n",
    "params,\n",
    "train_data,\n",
    "valid_sets=[train_data, test_data],\n",
    "callbacks=[early_stopping(stopping_rounds=10), log_evaluation(10)]\n",
    ")\n",
    "\n",
    "test['xgb_pred'] = model_lgb.predict(X_test)\n",
    "score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "score_naive = naive_forecast(train, test)\n",
    "naive_list.append(score_naive)\n",
    "xgb_list.append(score_xgb)\n",
    "df_rmse = pd.DataFrame({\n",
    "    'XGB_rmse': xgb_list,\n",
    "    'Naive_rmse': naive_list\n",
    "})\n",
    "df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['XGB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['XGB_rmse']\n",
    "df_rmse\n",
    "\n",
    "# # Evaluate the model\n",
    "# rmse = root_mean_squared_error(y_test, y_pred, squared=False)\n",
    "# print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83129aee-0691-43b4-ad56-bf6fb7886cc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### LightGBM with distance and detailedcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ce1a3ca-5380-4df2-bd5d-d31db2b8991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 6.42971\tvalid_1's rmse: 5.54192\n",
      "[20]\ttraining's rmse: 4.8333\tvalid_1's rmse: 3.81498\n",
      "[30]\ttraining's rmse: 4.36723\tvalid_1's rmse: 3.54509\n",
      "[40]\ttraining's rmse: 4.183\tvalid_1's rmse: 3.57063\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's rmse: 4.34326\tvalid_1's rmse: 3.51961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_rmse</th>\n",
       "      <th>Naive_rmse</th>\n",
       "      <th>smaller</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.519609</td>\n",
       "      <td>5.159748</td>\n",
       "      <td>xgb</td>\n",
       "      <td>1.640139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB_rmse  Naive_rmse smaller  Difference\n",
       "0  3.519609    5.159748     xgb    1.640139"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical_features = ['DetailedCat']\n",
    "categorical_features = ['DetailedCat','Analyte']\n",
    "# Initialize empty lists to store the values\n",
    "xgb_list = []\n",
    "naive_list = []\n",
    "Analyte_list = []\n",
    "# features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Distance','DetailedCat']\n",
    "features = ['month', 'quarter', 'weekofyear','lag_1','lag_2','Distance','DetailedCat','Analyte']\n",
    "target = 'Consump1'\n",
    "pct = 0.8\n",
    "\n",
    "data_input['Facility'] = data_input['Facility'].astype('category')\n",
    "data_input1=data_input.copy()\n",
    "train, test = split_train_test(data_input1,pct)\n",
    "X_train,y_train, X_test, y_test = x_y(data_input1,pct,features,target)\n",
    "# Convert data to LightGBM Dataset format and specify categorical features\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "# Define parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',  # Use 'regression' for predicting continuous values\n",
    "    'metric': 'rmse',           # Use root mean squared error for evaluation\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "model_lgb = lgb.train(\n",
    "params,\n",
    "train_data,\n",
    "valid_sets=[train_data, test_data],\n",
    "callbacks=[early_stopping(stopping_rounds=10), log_evaluation(10)]\n",
    ")\n",
    "\n",
    "test['xgb_pred'] = model_lgb.predict(X_test)\n",
    "score_xgb = np.sqrt(mean_squared_error(test['Consump1'], test['xgb_pred']))\n",
    "score_naive = naive_forecast(train, test)\n",
    "naive_list.append(score_naive)\n",
    "xgb_list.append(score_xgb)\n",
    "df_rmse = pd.DataFrame({\n",
    "    'XGB_rmse': xgb_list,\n",
    "    'Naive_rmse': naive_list\n",
    "})\n",
    "df_rmse['smaller'] = df_rmse.apply(lambda row: 'xgb' if row['XGB_rmse'] < row['Naive_rmse'] else 'naive', axis=1)\n",
    "df_rmse['Difference'] = df_rmse['Naive_rmse']-df_rmse['XGB_rmse']\n",
    "df_rmse\n",
    "\n",
    "# # Evaluate the model\n",
    "# rmse = root_mean_squared_error(y_test, y_pred, squared=False)\n",
    "# print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
